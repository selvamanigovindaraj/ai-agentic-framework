# LLM Provider Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
AZURE_OPENAI_KEY=your_azure_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Default Model Settings
DEFAULT_MODEL=gpt-4
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000

# Vector Database Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp
CHROMA_HOST=localhost
CHROMA_PORT=8000

# Redis Configuration (for short-term memory and caching)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Observability
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_SERVICE_NAME=agentic-framework
ENABLE_TELEMETRY=true

# Agent Configuration
MAX_AGENT_ITERATIONS=10
AGENT_TIMEOUT_SECONDS=300
ENABLE_SANDBOX=true

# Cost Controls
MAX_COST_PER_REQUEST=1.00
MAX_TOKENS_PER_DAY=1000000

# Security
ENABLE_GUARDRAILS=true
REQUIRE_TOOL_SIGNATURES=false

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
